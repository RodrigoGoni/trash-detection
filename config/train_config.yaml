# Object Detection Training Configuration

# Experiment settings
experiment:
  name: "taco_detection_mobilenet_cb_focal_full_aug"
  tags:
    - "full_augmentation"
    - "geometric_aug"
    - "photometric_aug"
    - "blur_noise_aug"
    - "cutout_aug"
    - "cb_focal_loss"
    - "class_weights"
    - "adamw_optimizer"
    - "cosine_scheduler"
    - "faster_rcnn"
    - "mobilenet_v3_large"
  description: "Faster R-CNN with MobileNetV3-Large backbone for TACO dataset with full augmentation pipeline"

# Data settings
data:
  processed_dir: "./data/processed"
  batch_size: 16
  num_workers: 20
  img_size: 640
  dataset_version: "v1.0"  # Track dataset version
  
  # Preprocessing parameters (will be logged to MLflow)
  preprocessing:
    normalize: true
    mean: [0.485, 0.456, 0.406]
    std: [0.229, 0.224, 0.225]
    bbox_format: "pascal_voc"
  
  # Augmentation parameters for train set
  # Configuración ajustada basada en características del dataset TACO:
  # - Imágenes con alta variabilidad en brillo (22-208), contraste (15-83) y ruido (2-14236)
  # - Objetos de basura pueden aparecer en cualquier orientación
  # - Escenas al aire libre con diferentes condiciones de iluminación
  augmentation:
    # Geometric augmentations
    # Basura puede estar en cualquier orientación en ambientes naturales
    horizontal_flip_p: 0.5      # 50% - común en objetos de basura
    vertical_flip_p: 0.3        # 30% - menos común pero posible
    shift_scale_rotate_p: 0.7   # 70% - importante para objetos en diferentes posiciones
    shift_limit: 0.1            # ±10% - evita perder objetos en bordes
    scale_limit: 0.6            # ±20% - objetos a diferentes distancias
    rotate_limit: 90            # ±20° - basura puede estar en varias orientaciones
    
    # Photometric augmentations
    # Dataset tiene gran variabilidad: brillo (22-208), contraste (15-83)
    brightness_contrast_p: 0.6  # 60% - crítico para robustez
    brightness_limit: 0.25      # ±25% - cubre rango del dataset
    contrast_limit: 0.25        # ±25% - importante variación observada
    
    hue_saturation_p: 0.4       # 40% - diferentes condiciones de luz
    hue_shift_limit: 15         # ±15 - variaciones de color razonables
    sat_shift_limit: 25         # ±25 - saturación variable en exteriores
    val_shift_limit: 20         # ±20 - valor de brillo
    
    # Blur augmentations
    # Dataset tiene ruido variable (promedio 1169, max 14236)
    blur_p: 0.3                 # 30% - algunas imágenes son borrosas
    blur_limit: 5               # Max 5px - blur moderado
    
    # Noise augmentations
    # Alto nivel de ruido en algunas imágenes del dataset
    noise_p: 0.25               # 25% - simula ruido de cámara
    
    # Cutout/dropout augmentations
    # Ayuda con oclusiones parciales (basura puede estar parcialmente cubierta)
    cutout_p: 0.2               # 20% - oclusión moderada
    cutout_max_holes: 3         # Max 3 huecos
    cutout_max_height: 40       # 40px - pequeños huecos
    cutout_max_width: 40        # 40px - pequeños huecos

# Model settings
# ============================================================
# ARQUITECTURAS SOPORTADAS:
# ============================================================
#
# 1. Faster R-CNN (Two-stage detector):
#    name: "FasterRCNN"
#    Backbones disponibles:
#      - 'resnet50': ResNet50-FPN (baseline, robusto)
#      - 'mobilenet_v3_large': MobileNetV3-Large-FPN (moderno, eficiente, recomendado)
#      - 'mobilenet_v3_large_320': MobileNetV3-Large-320-FPN (más rápido)
#    Soporte completo: CB Focal Loss, class weights, custom losses
#
# 2. YOLOv11 (One-stage detector, más rápido):
#    name: "YOLOv11"
#    Model sizes disponibles:
#      - 'n': nano (más rápido, menor precisión)
#      - 's': small (balance recomendado)
#      - 'm': medium (más preciso)
#      - 'l': large (muy preciso, más lento)
#      - 'x': extra large (máxima precisión)
#    Soporte: class weights, optimizers personalizados
#    Nota: Custom losses aproximadas mediante parámetros de YOLO
#
# ============================================================
model:
  name: "FasterRCNN"  # Opciones: "FasterRCNN" o "YOLOv11"
  
  # Para Faster R-CNN:
  backbone: "mobilenet_v3_large"
  
  # Para YOLOv11 (descomentarname: "YOLOv11" arriba):
  # model_size: "s"  # Opciones: 'n', 's', 'm', 'l', 'x'
  
  pretrained: true
  num_classes: 61  # 60 classes + 1 background (para Faster R-CNN)
                   # 60 classes sin background (para YOLO)

# Training settings
training:
  num_epochs: 50
  device: "cuda"
  
  # Optimizer - AdamW (modern best practice for vision)
  optimizer:
    type: "adamw"              # AdamW with decoupled weight decay
    lr: 0.0001                 # Lower LR for AdamW (typical: 1e-4 to 1e-3)
    betas: [0.9, 0.999]        # Adam betas (momentum-like parameters)
    weight_decay: 0.01         # L2 regularization (decoupled in AdamW)
    eps: 0.00000001            # Numerical stability (1e-8)
  
  # Scheduler - Cosine Annealing with Warmup (modern best practice)
  scheduler:
    type: "cosine_annealing_warmup"  # Smooth decay to 0
    warmup_epochs: 5                 # Linear warmup for first 5 epochs
    min_lr: 0.000001                 # Minimum learning rate at end (1e-6)
    # Cosine annealing will smoothly reduce LR from initial to min_lr
  
  # Loss function for imbalanced classes
  loss:
    type: "cb_focal"                 # Options: 'ce' (CrossEntropy), 'focal', 'cb_focal' (Class-Balanced Focal)
    
    # Class weighting strategy
    use_class_weights: true   # Enable class weighting
    class_weight_method: "effective"  # Options: 'inverse', 'effective', 'sqrt'
    
    # Focal Loss parameters (applies to 'focal' and 'cb_focal')
    gamma: 2.0                 # Focusing parameter (0 = CE, 2 = standard, higher = more focus on hard)
    
    # Class-Balanced Loss parameters (applies to 'cb_focal')
    beta: 0.9999               # Effective number beta (0.999-0.9999 for TACO)
                              # Higher beta = more emphasis on rare classes
    
    # Bounding box loss
    bbox_loss_weight: 1.0      # Weight for bbox regression loss
    use_weighted_bbox: true   # Apply class weights to bbox loss
  
  # Mixed Precision Training (for faster training and less memory)
  use_amp: true                # Automatic Mixed Precision (FP16)
  
  # Gradient Clipping (prevent exploding gradients)
  grad_clip_norm: 1.0          # Clip gradients to max norm of 1.0
  
  # Checkpointing
  save_dir: "./models/checkpoints"
  save_best_only: true
  
  # Validation
  val_frequency: 1  # Validate every N epochs
  
  # Early stopping
  patience: 15                 # Increased patience for cosine annealing

# MLflow settings
mlflow:
  tracking_uri: "./mlruns"
  experiment_name: "taco-object-detection"
  log_model: true
  log_artifacts: true
